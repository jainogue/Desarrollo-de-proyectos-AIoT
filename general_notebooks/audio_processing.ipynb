{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga y procesado de datos\n",
    "\n",
    "## Audios  de ruido para test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga de la base de datos de kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files(\"mmoreaux/environmental-sound-classification-50\", path='../data_test/noise', unzip=True)\n",
    "\n",
    "print(\"Audios de ruido descargados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción de los archivos de audio a la carpeta de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "SRC_DIR   = '../data_test/noise/audio/audio'\n",
    "DEST_DIR  = '../data_test/noise'\n",
    "\n",
    "# Crear la carpeta destino si no existe\n",
    "os.makedirs(DEST_DIR, exist_ok=True)\n",
    "\n",
    "# Recorrer recursivamente SRC_DIR\n",
    "for root, _, files in os.walk(SRC_DIR):\n",
    "    for fname in files:\n",
    "        src_path = os.path.join(root, fname)\n",
    "        if fname.lower().endswith('.wav'):\n",
    "            dest_path = os.path.join(DEST_DIR, fname)\n",
    "            base, ext = os.path.splitext(fname)\n",
    "            counter = 1\n",
    "            while os.path.exists(dest_path):\n",
    "                dest_path = os.path.join(DEST_DIR, f\"{base}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "print(\"Todos los WAV han sido copiados a:\", DEST_DIR)\n",
    "\n",
    "# Eliminar de DEST_DIR cualquier fichero que no sea .wav\n",
    "for fname in os.listdir(DEST_DIR):\n",
    "    path = os.path.join(DEST_DIR, fname)\n",
    "    if os.path.isfile(path) and not fname.lower().endswith('.wav'):\n",
    "        os.remove(path)\n",
    "        print(\"Eliminado:\", fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audios de llanto para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files(\"warcoder/infant-cry-audio-corpus\", path='../data_test/crying', unzip=True)\n",
    "\n",
    "print(\"Downloaded preprocess-audio dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta raíz donde están las subcarpetas con los WAV\n",
    "ROOT_DIR = '../data_test/crying'\n",
    "\n",
    "# Recorrer recursivamente ROOT_DIR moviendo todos los .wav al nivel superior\n",
    "for current_dir, _, files in os.walk(ROOT_DIR):\n",
    "    if os.path.abspath(current_dir) == os.path.abspath(ROOT_DIR):\n",
    "        continue\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith('.wav'):\n",
    "            src_path = os.path.join(current_dir, fname)\n",
    "            dest_path = os.path.join(ROOT_DIR, fname)\n",
    "            base, ext = os.path.splitext(fname)\n",
    "            counter = 1\n",
    "            while os.path.exists(dest_path):\n",
    "                dest_path = os.path.join(ROOT_DIR, f\"{base}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "# Eliminar todo lo que no sea .wav en ROOT_DIR\n",
    "for entry in os.listdir(ROOT_DIR):\n",
    "    path = os.path.join(ROOT_DIR, entry)\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    elif os.path.isfile(path) and not entry.lower().endswith('.wav'):\n",
    "        os.remove(path)\n",
    "print(\"\\n Proceso completado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import librosa\n",
    "\n",
    "# Parámetros\n",
    "SAMPLE_RATE        = 16000\n",
    "DURATION           = 1\n",
    "SAMPLES_PER_AUDIO  = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Directorios\n",
    "RAW_DATA_DIR        = \"../data_train/raw\"\n",
    "PROCESSED_DATA_DIR  = \"../data_train/processed_audio\"\n",
    "TRAIN_PATH          = os.path.join(PROCESSED_DATA_DIR, \"train.npz\")\n",
    "TEST_PATH           = os.path.join(PROCESSED_DATA_DIR, \"test.npz\")\n",
    "TEST_SPLIT          = 0.2\n",
    "NUM_CLASSES         = 2\n",
    "\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "def load_audio(file_path, target_sr=SAMPLE_RATE):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
    "    except Exception as e:\n",
    "        print(f\"No se puede leer {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if len(audio) > SAMPLES_PER_AUDIO:\n",
    "        start = (len(audio) - SAMPLES_PER_AUDIO) // 2\n",
    "        audio = audio[start:start + SAMPLES_PER_AUDIO]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, SAMPLES_PER_AUDIO - len(audio)), mode='constant')\n",
    "\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    if max_val > 0:\n",
    "        audio = audio / max_val\n",
    "\n",
    "    return audio.astype(np.float32)\n",
    "\n",
    "def process_and_save_data(raw_data_dir, processed_data_dir):\n",
    "    # Recopilar rutas de archivos por categoría\n",
    "    categories = [(\"crying\", 0), (\"noise\", 1)]\n",
    "    file_paths = {}\n",
    "    for cat, _ in categories:\n",
    "        cat_dir = os.path.join(raw_data_dir, cat)\n",
    "        if not os.path.isdir(cat_dir):\n",
    "            print(f\"El directorio {cat_dir} no existe, saltando...\")\n",
    "            file_paths[cat] = []\n",
    "            continue\n",
    "        all_files = [os.path.join(cat_dir, fn)\n",
    "                     for fn in os.listdir(cat_dir)\n",
    "                     if fn.lower().endswith(('.wav', '.ogg'))]\n",
    "        file_paths[cat] = all_files\n",
    "\n",
    "    # Calcular el tamaño mínimo entre clases\n",
    "    counts = [len(file_paths[cat]) for cat, _ in categories]\n",
    "    if min(counts) == 0:\n",
    "        print(\"Error: alguna clase no tiene archivos.\")\n",
    "        return\n",
    "    n_per_class = min(counts)\n",
    "\n",
    "    # Seleccionar aleatoriamente n_per_class de cada categoría\n",
    "    random.seed(42)\n",
    "    for cat, _ in categories:\n",
    "        random.shuffle(file_paths[cat])\n",
    "        file_paths[cat] = file_paths[cat][:n_per_class]\n",
    "\n",
    "    # Cargar, procesar y etiquetar\n",
    "    audio_data = []\n",
    "    labels     = []\n",
    "    for cat, label in categories:\n",
    "        for file_path in file_paths[cat]:\n",
    "            audio = load_audio(file_path)\n",
    "            if audio is not None:\n",
    "                audio_data.append(audio)\n",
    "                labels.append(label)\n",
    "\n",
    "    # Convertir a arrays y dividir train/test\n",
    "    X = np.stack(audio_data)\n",
    "    y = np.array(labels, dtype=np.int32)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=TEST_SPLIT,\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # One-hot encoding\n",
    "    y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "    y_test  = to_categorical(y_test,  num_classes=NUM_CLASSES)\n",
    "\n",
    "    # Guardar\n",
    "    np.savez_compressed(TRAIN_PATH, X=X_train, y=y_train)\n",
    "    np.savez_compressed(TEST_PATH,  X=X_test,  y=y_test)\n",
    "\n",
    "    print(\"Datos procesados y guardados:\")\n",
    "    print(f\"  Cada clase: {n_per_class} muestras\")\n",
    "    print(f\"  Train -> {TRAIN_PATH}: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"  Test  -> {TEST_PATH}: X={X_test.shape},  y={y_test.shape}\")\n",
    "\n",
    "process_and_save_data(RAW_DATA_DIR, PROCESSED_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se implementa un código para visualizar los audios porcesados y observar la normalización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Rutas de los datos\n",
    "TRAIN_PATH = \"../data_train/processed_audio/train.npz\"\n",
    "TEST_PATH = \"../data_train/processed_audio/test.npz\"\n",
    "\n",
    "# Cargar datos procesados\n",
    "data_train = np.load(TRAIN_PATH)\n",
    "data_test = np.load(TEST_PATH)\n",
    "\n",
    "# Extraer datos y etiquetas\n",
    "X_train, y_train = data_train[\"X\"], data_train[\"y\"]\n",
    "X_test, y_test = data_test[\"X\"], data_test[\"y\"]\n",
    "\n",
    "# Imprimir información sobre los datos\n",
    "print(\"Datos cargados correctamente:\")\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")  # (n_samples, SAMPLES_PER_AUDIO)\n",
    "print(f\"Test:  X={X_test.shape}, y={y_test.shape}\")    # (n_samples, SAMPLES_PER_AUDIO)\n",
    "\n",
    "# Diccionario de etiquetas\n",
    "labels = [\"crying\", \"noise\"]\n",
    "\n",
    "# Seleccionar múltiples muestras aleatorias\n",
    "num_samples = 5\n",
    "sample_indices = random.sample(range(len(X_test)), num_samples)\n",
    "\n",
    "\n",
    "labels = [\"crying\", \"noise\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_samples, 1, figsize=(10, 2 * num_samples))\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    input_data = X_test[idx]\n",
    "    real_class = np.argmax(y_test[idx])\n",
    "\n",
    "    axes[i].plot(X_test[idx])\n",
    "    axes[i].set_title(f\"Ejemplo {idx}:, Real={labels[real_class]}\")\n",
    "    axes[i].set_xlabel(\"Muestras\")\n",
    "    axes[i].set_ylabel(\"Amplitud\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versiones MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.fftpack\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Parámetros globales\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 1\n",
    "SAMPLES_PER_AUDIO = SAMPLE_RATE * DURATION\n",
    "\n",
    "N_MFCC = 13\n",
    "N_FFT = 640\n",
    "HOP_LENGTH = 320\n",
    "MAX_LEN = 49\n",
    "NUM_MEL_FILTERS = 26\n",
    "EPSILON = 1e-8\n",
    "\n",
    "# Directorios\n",
    "RAW_DATA_DIR        = \"../data_train/raw\"\n",
    "PROCESSED_DATA_DIR  = \"../data_train/processed_MFCC\"\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "def hz_to_mel(hz):\n",
    "    return 2595.0 * np.log10(1.0 + hz / 700.0)\n",
    "\n",
    "def mel_to_hz(mel):\n",
    "    return 700.0 * (10**(mel / 2595.0) - 1.0)\n",
    "\n",
    "def load_audio(file_path, target_sr=SAMPLE_RATE, epsilon=EPSILON):\n",
    "    try:\n",
    "        audio, sr = sf.read(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if audio.size == 0:\n",
    "        return None\n",
    "\n",
    "    # Mono\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    # Resample\n",
    "    if sr != target_sr:\n",
    "        num_samples = int(len(audio) * target_sr / sr)\n",
    "        if num_samples <= 0:\n",
    "            return None\n",
    "        audio = scipy.signal.resample(audio, num_samples)\n",
    "    # Truncar/pad\n",
    "    if len(audio) > SAMPLES_PER_AUDIO:\n",
    "        audio = audio[:SAMPLES_PER_AUDIO]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, SAMPLES_PER_AUDIO - len(audio)), mode='constant')\n",
    "    # Normalizar\n",
    "    audio -= np.mean(audio)\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    if max_val > 0:\n",
    "        audio /= (max_val + epsilon)\n",
    "\n",
    "    # MFCC\n",
    "    frame_len = N_FFT\n",
    "    frame_step = HOP_LENGTH\n",
    "    num_frames = (len(audio) - frame_len) // frame_step + 1\n",
    "    frames_to_process = min(num_frames, MAX_LEN)\n",
    "    window = np.hamming(frame_len)\n",
    "\n",
    "    # Mel filter bank\n",
    "    num_mel_points = NUM_MEL_FILTERS + 2\n",
    "    mel_low = hz_to_mel(0.0)\n",
    "    mel_high = hz_to_mel(target_sr/2)\n",
    "    mel_points = np.linspace(mel_low, mel_high, num_mel_points)\n",
    "    hz_points = mel_to_hz(mel_points)\n",
    "    bin_indices = np.floor((frame_len+1)*hz_points/target_sr).astype(int)\n",
    "\n",
    "    mfcc_feats = []\n",
    "    for m in range(frames_to_process):\n",
    "        start = m*frame_step\n",
    "        frame = audio[start:start+frame_len] * window\n",
    "        spectrum = np.fft.rfft(frame)\n",
    "        power_spec = (np.abs(spectrum)**2)/frame_len\n",
    "\n",
    "        # Mel energies\n",
    "        mel_energies = np.zeros(NUM_MEL_FILTERS)\n",
    "        for i in range(1, num_mel_points-1):\n",
    "            start_b, center_b, end_b = bin_indices[i-1], bin_indices[i], bin_indices[i+1]\n",
    "            # ascend\n",
    "            mel_energies[i-1] += np.sum(\n",
    "                power_spec[start_b:center_b] *\n",
    "                (np.arange(start_b,center_b)-start_b)/(center_b-start_b+epsilon)\n",
    "            )\n",
    "            # descend\n",
    "            mel_energies[i-1] += np.sum(\n",
    "                power_spec[center_b:end_b] *\n",
    "                (end_b-np.arange(center_b,end_b))/(end_b-center_b+epsilon)\n",
    "            )\n",
    "        log_mel = np.log(mel_energies + epsilon)\n",
    "        dct_res = scipy.fftpack.dct(log_mel, type=2, norm='ortho')\n",
    "        mfcc_feats.append(dct_res[:N_MFCC])\n",
    "\n",
    "    # Padding si faltan frames\n",
    "    if frames_to_process < MAX_LEN:\n",
    "        for _ in range(MAX_LEN-frames_to_process):\n",
    "            mfcc_feats.append(np.zeros(N_MFCC, dtype=np.float32))\n",
    "\n",
    "    return np.array(mfcc_feats, dtype=np.float32)\n",
    "\n",
    "def process_and_save_data(raw_data_dir, processed_data_dir):\n",
    "    # Listar archivos por clase\n",
    "    crying_dir = os.path.join(raw_data_dir, \"crying\")\n",
    "    noise_dir  = os.path.join(raw_data_dir, \"noise\")\n",
    "\n",
    "    crying_files = [os.path.join(crying_dir, f)\n",
    "                    for f in os.listdir(crying_dir)\n",
    "                    if f.lower().endswith(('.wav','.ogg'))] \\\n",
    "                   if os.path.isdir(crying_dir) else []\n",
    "    noise_files  = [os.path.join(noise_dir, f)\n",
    "                    for f in os.listdir(noise_dir)\n",
    "                    if f.lower().endswith(('.wav','.ogg'))] \\\n",
    "                   if os.path.isdir(noise_dir) else []\n",
    "\n",
    "    if not crying_files or not noise_files:\n",
    "        print(\"Una de las carpetas 'crying' o 'noise' está vacía o no existe.\")\n",
    "        return\n",
    "\n",
    "    # Determinar mínimo\n",
    "    n_per_class = min(len(crying_files), len(noise_files))\n",
    "    random.seed(42)\n",
    "    crying_files = random.sample(crying_files, n_per_class)\n",
    "    noise_files  = random.sample(noise_files,  n_per_class)\n",
    "\n",
    "    # Procesar y etiquetar\n",
    "    X, y = [], []\n",
    "    for path in crying_files:\n",
    "        feats = load_audio(path)\n",
    "        if feats is not None:\n",
    "            X.append(feats); y.append(0)\n",
    "    for path in noise_files:\n",
    "        feats = load_audio(path)\n",
    "        if feats is not None:\n",
    "            X.append(feats); y.append(1)\n",
    "    if not X:\n",
    "        print(\"No se procesó ningún audio válido.\")\n",
    "        return\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y, dtype=int)\n",
    "\n",
    "    # Dividir train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # One-hot\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_test  = to_categorical(y_test,  num_classes=2)\n",
    "\n",
    "    # Guardar\n",
    "    train_path = os.path.join(processed_data_dir, \"train.npz\")\n",
    "    test_path  = os.path.join(processed_data_dir, \"test.npz\")\n",
    "    np.savez_compressed(train_path, X=X_train, y=y_train)\n",
    "    np.savez_compressed(test_path,  X=X_test,  y=y_test)\n",
    "\n",
    "    print(f\"Procesados {n_per_class} muestras por clase.\")\n",
    "    print(f\"Train: {train_path} -> X{X_train.shape}, y{y_train.shape}\")\n",
    "    print(f\"Test : {test_path}  -> X{X_test.shape},  y{y_test.shape}\")\n",
    "\n",
    "\n",
    "process_and_save_data(RAW_DATA_DIR, PROCESSED_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script para visualizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# Rutas de los datos\n",
    "TRAIN_PATH = \"../data_train/processed_MFCC/train.npz\"\n",
    "TEST_PATH = \"../data_train/processed_MFCC/test.npz\"\n",
    "\n",
    "# Cargar datos procesados\n",
    "data_train = np.load(TRAIN_PATH)\n",
    "data_test = np.load(TEST_PATH)\n",
    "\n",
    "# Extraer datos y etiquetas\n",
    "X_train, y_train = data_train[\"X\"], data_train[\"y\"]\n",
    "X_test, y_test = data_test[\"X\"], data_test[\"y\"]\n",
    "\n",
    "# Imprimir información sobre los datos\n",
    "print(\"Datos cargados correctamente:\")\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")  # Ej.: (n_samples, MAX_LEN, N_MFCC)\n",
    "print(f\"Test:  X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Diccionario de etiquetas\n",
    "labels = [\"crying\", \"noise\"]\n",
    "\n",
    "# Seleccionar múltiples muestras aleatorias\n",
    "num_samples = 5\n",
    "sample_indices = random.sample(range(len(X_test)), num_samples)\n",
    "\n",
    "# Crear gráfica para visualizar MFCC\n",
    "fig, axes = plt.subplots(num_samples, 1, figsize=(10, 2 * num_samples))\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    mfcc_data = X_test[idx]\n",
    "    real_class = np.argmax(y_test[idx])\n",
    "    im = axes[i].imshow(mfcc_data.T, aspect='auto', origin='lower', interpolation='nearest')\n",
    "    axes[i].set_title(f\"Ejemplo {idx}: Real = {labels[real_class]}\")\n",
    "    axes[i].set_xlabel(\"Frame\")\n",
    "    axes[i].set_ylabel(\"Coeficiente MFCC\")\n",
    "    fig.colorbar(im, ax=axes[i])\n",
    "\n",
    "    print(\"Ejemplo seleccionado (índice {}):\".format(sample_indices[0]))\n",
    "    print(X_test[sample_indices[0]])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
