{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaee9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data_train/processed_audio/train.npz\"\n",
    "TEST_PATH = \"../data_train/processed_audio/test.npz\"\n",
    "\n",
    "data_train = np.load(TRAIN_PATH)\n",
    "data_test = np.load(TEST_PATH)\n",
    "\n",
    "X_train, y_train = data_train[\"X\"], data_train[\"y\"]\n",
    "X_test, y_test = data_test[\"X\"], data_test[\"y\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((tf.cast(X_train, tf.float32), y_train))\n",
    "    .cache()\n",
    "    .shuffle(buffer_size=len(X_train))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((tf.cast(X_test, tf.float32), y_test))\n",
    "    .cache()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24a2e4",
   "metadata": {},
   "source": [
    "# Compresión de modelos a Tensorflow Lite\n",
    "\n",
    "## Cuantización completa a enteros de 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "MODEL_H5_PATH = \"../models/not_compressed_audio/model_CNNA.h5\"\n",
    "TFLITE_PATH = \"../models/compressed_int8/model_CNNA.tflite\"\n",
    "\n",
    "\n",
    "# Dataset representativo para calibración de int8\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        sample = X_train[i].astype(np.float32)[np.newaxis, :]\n",
    "        yield [sample]\n",
    "\n",
    "# Cargar el modelo H5 entrenado\n",
    "model = tf.keras.models.load_model(MODEL_H5_PATH)\n",
    "\n",
    "# Preparar el convertidor TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Convertir y guardar\n",
    "tflite_quant = converter.convert()\n",
    "with open(TFLITE_PATH, \"wb\") as f:\n",
    "    f.write(tflite_quant)\n",
    "\n",
    "print(\"Modelo TFLite guardado en:\", TFLITE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036b5c0",
   "metadata": {},
   "source": [
    "Script para ver las operaciones  que realiza  el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a977599",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_PATH = '../models/compressed_int8/model_NN.tflite'\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Verificar tipo de entrada/salida\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"Tipo de entrada: {input_details[0]['dtype']} \")\n",
    "print(f\"Tipo de salida: {output_details[0]['dtype']} \")\n",
    "\n",
    "# Verificar operaciones utilizadas\n",
    "ops_set = set()\n",
    "for idx in range(len(interpreter._get_ops_details())):\n",
    "    op_name = interpreter._get_ops_details()[idx]['op_name']\n",
    "    ops_set.add(op_name)\n",
    "\n",
    "print(\"\\nOperaciones utilizadas en el modelo TFLite:\")\n",
    "for op in sorted(ops_set):\n",
    "    print(f\"{op}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed244184",
   "metadata": {},
   "source": [
    "Script para pasa  los modelos  a un archivo binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "INT8_TFLITE_PATH = \"../models/compressed_int8/model_NN.tflite\"\n",
    "CPP_PATH = \"../V_int8/main/model.cpp\"\n",
    "HEADER_PATH = \"../V_int8/main/model.hpp\"\n",
    "\n",
    "# Cargar modelo TFLite cuantizado\n",
    "with open(INT8_TFLITE_PATH, \"rb\") as f:\n",
    "    tflite_model = f.read()\n",
    "\n",
    "#Convertir a array de bytes en formato C++\n",
    "cpp_array = \", \".join(str(b) for b in tflite_model)\n",
    "\n",
    "# Generar código C++ (`model.cpp`)\n",
    "cpp_code = f\"\"\"#include \"model.hpp\"\n",
    "\n",
    "alignas(8) const unsigned char model_tflite[] = {{\n",
    "    {cpp_array}\n",
    "}};\n",
    "\n",
    "const int model_tflite_len = {len(tflite_model)};\n",
    "\"\"\"\n",
    "\n",
    "# Guardar `model.cpp`\n",
    "with open(CPP_PATH, \"w\") as f:\n",
    "    f.write(cpp_code)\n",
    "\n",
    "# Generar código C++ (`model.hpp`)\n",
    "header_code = \"\"\"#ifndef MODEL_H_\n",
    "#define MODEL_H_\n",
    "\n",
    "extern const unsigned char model_tflite[];\n",
    "extern const int model_tflite_len;\n",
    "\n",
    "#endif  // MODEL_H_\n",
    "\"\"\"\n",
    "\n",
    "# Guardar `model.h`\n",
    "with open(HEADER_PATH, \"w\") as f:\n",
    "    f.write(header_code)\n",
    "\n",
    "print(f\"Modelo exportado a C++ en {CPP_PATH}\")\n",
    "print(f\"Header guardado en {HEADER_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a2bf1",
   "metadata": {},
   "source": [
    "## Conversión a TFLite sin cuantizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e34d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_H5_PATH = \"../models/not_compressed_audio/model_CNNA.h5\"\n",
    "FLOAT_TFLITE_PATH = \"../models/compressed_float32/model_CNNA.tflite\"\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_H5_PATH)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "tflite_model = converter.convert()\n",
    "with open(FLOAT_TFLITE_PATH, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Modelo cuantizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f231f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_PATH = '../models/compressed_float32/model_CNN.tflite'\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"Tipo de entrada: {input_details[0]['dtype']} \")\n",
    "print(f\"Tipo de salida: {output_details[0]['dtype']} \")\n",
    "\n",
    "ops_set = set()\n",
    "for idx in range(len(interpreter._get_ops_details())):\n",
    "    op_name = interpreter._get_ops_details()[idx]['op_name']\n",
    "    ops_set.add(op_name)\n",
    "\n",
    "print(\"\\nOperaciones utilizadas en el modelo TFLite:\")\n",
    "for op in sorted(ops_set):\n",
    "    print(f\"{op}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "FLOAT_TFLITE_PATH = \"../models/compressed_float32/model_CNNA.tflite\"\n",
    "CPP_PATH = \"../V_float/main/model.cpp\"\n",
    "HEADER_PATH = \"../V_float/main/model.hpp\"\n",
    "\n",
    "\n",
    "with open(FLOAT_TFLITE_PATH, \"rb\") as f:\n",
    "    tflite_model = f.read()\n",
    "\n",
    "\n",
    "cpp_array = \", \".join(str(b) for b in tflite_model)\n",
    "\n",
    "\n",
    "cpp_code = f\"\"\"#include \"model.hpp\"\n",
    "\n",
    "alignas(8) const unsigned char model_tflite[] = {{\n",
    "    {cpp_array}\n",
    "}};\n",
    "\n",
    "const int model_tflite_len = {len(tflite_model)};\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(CPP_PATH, \"w\") as f:\n",
    "    f.write(cpp_code)\n",
    "\n",
    "header_code = \"\"\"#ifndef MODEL_H_\n",
    "#define MODEL_H_\n",
    "\n",
    "extern const unsigned char model_tflite[];\n",
    "extern const int model_tflite_len;\n",
    "\n",
    "#endif  // MODEL_H_\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(HEADER_PATH, \"w\") as f:\n",
    "    f.write(header_code)\n",
    "\n",
    "print(f\"Modelo exportado a C++ en {CPP_PATH}\")\n",
    "print(f\"Header guardado en {HEADER_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2de87b",
   "metadata": {},
   "source": [
    "## Versiones MFCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de los datos procesados\n",
    "TRAIN_PATH = \"../data_train/processed_MFCC/train.npz\"\n",
    "TEST_PATH = \"../data_train/processed_MFCC/test.npz\"\n",
    "\n",
    "# Cargar datos\n",
    "data_train = np.load(TRAIN_PATH)\n",
    "data_test = np.load(TEST_PATH)\n",
    "\n",
    "X_train, y_train = data_train[\"X\"], data_train[\"y\"]\n",
    "X_test, y_test = data_test[\"X\"], data_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_H5_PATH = \"../models/not_compressed_MFCC/model_CNN.h5\"\n",
    "TFLITE_PATH = \"../models/compressed_MFCC/model_CNN.tflite\"\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_H5_PATH)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open(TFLITE_PATH, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Modelo cuantizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_PATH = \"../models/compressed_MFCC/model_CNNA.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"Tipo de entrada: {input_details[0]['dtype']} \")\n",
    "print(f\"Tipo de salida: {output_details[0]['dtype']} \")\n",
    "print(\"Formato de entrada esperado:\", model.input_shape)\n",
    "\n",
    "ops_set = set()\n",
    "for idx in range(len(interpreter._get_ops_details())):\n",
    "    op_name = interpreter._get_ops_details()[idx]['op_name']\n",
    "    ops_set.add(op_name)\n",
    "\n",
    "print(\"\\nOperaciones utilizadas en el modelo TFLite:\")\n",
    "for op in sorted(ops_set):\n",
    "    print(f\"{op}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TFLITE_PATH = \"../models/compressed_MFCC/model_CNN.tflite\"\n",
    "CPP_PATH = \"../V_MFCC/main/model.cpp\"\n",
    "HEADER_PATH = \"../V_MFCC/main/model.hpp\"\n",
    "\n",
    "\n",
    "with open(TFLITE_PATH, \"rb\") as f:\n",
    "    tflite_model = f.read()\n",
    "\n",
    "\n",
    "cpp_array = \", \".join(str(b) for b in tflite_model)\n",
    "\n",
    "cpp_code = f\"\"\"#include \"model.hpp\"\n",
    "\n",
    "alignas(8) const unsigned char model_tflite[] = {{\n",
    "    {cpp_array}\n",
    "}};\n",
    "\n",
    "const int model_tflite_len = {len(tflite_model)};\n",
    "\"\"\"\n",
    "\n",
    "with open(CPP_PATH, \"w\") as f:\n",
    "    f.write(cpp_code)\n",
    "header_code = \"\"\"#ifndef MODEL_H_\n",
    "#define MODEL_H_\n",
    "\n",
    "extern const unsigned char model_tflite[];\n",
    "extern const int model_tflite_len;\n",
    "\n",
    "#endif  // MODEL_H_\n",
    "\"\"\"\n",
    "with open(HEADER_PATH, \"w\") as f:\n",
    "    f.write(header_code)\n",
    "\n",
    "print(f\"Modelo exportado a C++ en {CPP_PATH}\")\n",
    "print(f\"Header guardado en {HEADER_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2838d9",
   "metadata": {},
   "source": [
    "## Comparación de técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f4932",
   "metadata": {},
   "source": [
    "Código para comparar tamaños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9616993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(n_bytes):\n",
    "    for unit in ['B','KB','MB','GB','TB']:\n",
    "        if n_bytes < 1024.0:\n",
    "            return f\"{n_bytes:.5f} {unit}\"\n",
    "        n_bytes /= 1024.0\n",
    "\n",
    "# Rutas a los modelos\n",
    "keras_path = \"../models/not_compressed_audio/model_NN.h5\"\n",
    "tflite_int8_path = \"../models/compressed_int8/model_NN.tflite\"\n",
    "tflite_float_path = \"../models/compressed_float32/model_NN.tflite\"\n",
    "\n",
    "size_keras  = os.path.getsize(keras_path)\n",
    "size_tflite_int8 = os.path.getsize(tflite_int8_path)\n",
    "size_tflite_float = os.path.getsize(tflite_float_path)\n",
    "\n",
    "print(\"Keras model:\", model_size(size_keras))\n",
    "print(\"TFLite int model:\", model_size(size_tflite_int8))\n",
    "print(\"TFLite float model:\", model_size(size_tflite_float))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
